# HermesLog

HermesLog is a novel federated split learning (FSL) framework. It enables collaborative training while ensuring data privacy and reducing the computational load on the client. It not only significantly lowers local computational load and privacy leakage but also preserves high diagnostic accuracy.

## ğŸ” Key Features

- **FL + SL Integration**: Collaborative training while ensuring data privacy and reducing the computational load on the client.
- **Multilayer privacy protection mechanism**: Combining feature filtering and irreversible protection techniques to effectively reduce reconstruction success and safeguard data privacy.
- **A model-splitting (SL-BERTï¼‰**: With the server sharing the backbone of the resource-intensive transformer and clients maintaining lightweight embeddings and personalized heads to reduce local computing power load.
- **The personalized local model via FedAvg and EMA (FL-EMA)**: Integrate component-driven log clustering with personalized fine-tuning to enhances modelâ€™s generalization and adaptability in heterogeneous environments.
- **Modular & Extensible**: Containerized deployment demonstrates enables rapid fault localization and recovery, effectively protecting enterprise data.

## ğŸ“„ Dataset Description
### This study evaluates two datasets:

  - **The publicly available Aliyun dataset:** link at https://tianchi.aliyun.com/competition/entrance/531947/information.  

  - **The Privacy unavailable ZTE datasets:** a proprietary dataset licensed from an industry partner, which cannot be publicly released. Access to the proprietary dataset requires authorization from the provider and a signed dataâ€‘use agreement.  

### Data storage and load:
  **dataset is divided into five parts, each representing the log data of an client-server, as shown in the following three files:**

- **1.The result of the log sequence after being vectorized by BERT**
```bash
data_{}.npy
```
- **2.Semi-supervised labels, where -1 indicates no label**
```bash
 semi_label_{}.npy
```
- **3.The label of the original data source**
```bash
 label_{}.npy
```

## ğŸ“ Icore code 

1. **Prompt-tuning**   

```bash
claude_zeroshot-cot.py
mistral_fewshot-cot.py
```

2. **Preference-tuning**
```bash
config.py
vllm_sample_offline.py
make_preference.py
run_train.py
```

3. **Knowledge Distillation**
```bash
XXX.py
```

## ğŸ“¦ Installation

```
conda create --name <env> --file requirements.txt
```




## ğŸ“ Project Structure
```
KDLog/
â”œâ”€â”€ code/               # Icore code (SL-Bert, FL-EMA, docker)
â”œâ”€â”€ data/               # Input logs
â”œâ”€â”€ requirements/       # Create an environment
â””â”€â”€ README.md           # Project description
```

```  
 Prompt-tuning/
â”œâ”€â”€ claude_zeroshot-cot-stage1.py
â”œâ”€â”€ data
â”‚Â Â  â””â”€â”€ output.json
â”œâ”€â”€ mistral_fewshot-cot-stage2.py
â”œâ”€â”€ monitor_gpu.sh
â”œâ”€â”€ output-stage1
â”‚Â Â  â”œâ”€â”€ claude.log
â”‚Â Â  â””â”€â”€ claude_results.json
â”œâ”€â”€ output-stage2-fewshot-cot
â”‚Â Â  â”œâ”€â”€ mistral.log
â”‚Â Â  â””â”€â”€ mistral_results.json
â”œâ”€â”€ README.md
â”œâ”€â”€ test_case_id.txt
â””â”€â”€ tree.txt
```

```
(base) âœ  dataset ls
claude_zeroshot-cot.py            output-stage2-fewshot-cot
data                              output-stage2-fewshot-nocot
mistral_fewshot-cot-stage2.py     output-stage2-zeroshot-cot
mistral_fewshot-nocot-stage2.py   output-stage2-zeroshot-nocot
mistral_zeroshot-cot-stage2.py    README.md
mistral_zeroshot-nocot-stage2.py  test_case_id.txt
monitor_gpu.sh                    tree.txt
output-stage1
```

```  
Preference-tuning/
â”œâ”€â”€ config.py
â”œâ”€â”€ vllm_sample_offline.py
â”œâ”€â”€ make_preference.py
â”œâ”€â”€ run_train.py
â””â”€â”€ vllm_sample_offline.py
```

```
Knowledge Distillation/
``` 

## ğŸ”— Links
- [Code](https://github.com/IoT1220/KDLog)








## é‡è¦æ–‡ä»¶


1. ä»£ç 

   ```
   cal_acc.py  make_preference.py  openai_multi_client.py  prompts.py         run_train.py  vllm_sample_offline.py
   config.py   make_sft.py         openai_rank.py          run_lora_merge.py  test.py       vllm_sample.py
   ```

2. ä¸­é—´è¿è¡Œæ‰€éœ€é…ç½®æ–‡ä»¶

   ```
   dpo.config.yaml  ipo.config.yaml  lora.merge.yaml  orpo.config.yaml  sft.config.yaml  temp.lora.merge.yaml  temp.yaml
   ```

   ä»¥åŠ`data/dataset_info.json`æ–‡ä»¶

3. æ‰¹é‡è¿è¡Œè·‘å®éªŒçš„è„šæœ¬åœ¨`scripts`æ–‡ä»¶å¤¹ä¸‹

   ```
   sample_aliyun.sh  sample_zte.sh  test_aliyun.sh  test_zte.sh  train_aliyun_sft.sh  train_aliyun.sh  train_zte.sh
   ```

## è¿è¡Œè¯´æ˜

1. è®¾ç½®datasetå¯¹åº”çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œè¯·ç¼–è¾‘`config.py`æ–‡ä»¶ï¼Œæ¯”å¦‚zteå¯¹åº”`ratio1224/ZTE/uncorrected`ï¼Œè¯·ç¡®ä¿è¯¥æ–‡ä»¶å¤¹ä¸‹æœ‰ç±»ä¼¼äº`train1+test1`çš„æ–‡ä»¶å¤¹ï¼Œåœ¨`ratio1224/ZTE/uncorrected/train1+test1`æ–‡ä»¶å¤¹è¿˜åº”è¯¥æœ‰`train.json`å’Œ`test.json`æ–‡ä»¶

2. é‡‡æ ·æ¨¡å‹å›å¤ï¼Œ`vllm_sample_offline.py`

   ```
   CUDA_VISIBLE_DEVICES=0,1,2,3 python vllm_sample_offline.py --model xxxx_path_to_model_folder --dataset zte --fewshot no --sample_n 5 --split train --run_split 1
   ```

   è¿™é‡Œé¢å¯ä»¥æŒ‡å®šæ˜¯å¦ä½¿ç”¨in-context learningï¼Œ`--fewshot no`å°±æ˜¯ä¸ä½¿ç”¨ï¼Œå¦‚æœ`yes`çš„è¯ï¼Œè¿˜å¯ä»¥æŒ‡å®šä½¿ç”¨å“ªäº›fewshot examplesï¼š`--fewshot_path xxx_path_to_file`ï¼›`--split train`å‚æ•°æŒ‡å®šäº†ä½¿ç”¨`train.json`ï¼Œ`--run_split 1`æŒ‡çš„æ˜¯ä½¿ç”¨`train1+test1`ï¼Œç›¸ä¼¼åœ°ï¼Œå¦‚æœæ˜¯`--run_split 2`ï¼Œé‚£ä¹ˆå°±æ˜¯`train2+test2`

3. æ¨¡å‹å›å¤é‡‡æ ·ç»“æŸåï¼Œæˆ‘ä»¬éœ€è¦åˆ¶ä½œpreference dataï¼Œ`make_preference.py`

   - é¦–å…ˆéœ€è¦æŠŠåˆšæ‰é‡‡æ ·å¾—åˆ°çš„æ–‡ä»¶`xxx.json`æ”¾åˆ°ä¸€ä¸ªå•ç‹¬çš„æ–‡ä»¶å¤¹ä¸­ï¼Œæ¯”å¦‚`preference_data_folder`

   - è¿è¡Œå‘½ä»¤ä¼šå¾—åˆ°åœ¨åŒæ–‡ä»¶å¤¹ä¸‹çš„ä¸€ä¸ª`preference_data.train.json`

     ```
     python make_preference.py --dataset zte --input_folder xxx_path_to_preference_data_folder
     ```

   - è¿™ä»½æ•°æ®å°†ç”¨æ¥åå¥½è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ç¼–è¾‘`data/dataset_info.json`ï¼Œç»™è¯¥æ•°æ®é›†å‘½åå¢åŠ ä¸€æ¡ï¼š

     ```
         "test_dataset_name": {
             "file_name": "xxxxx_path_to_file_preference_data.train.json",
             "ranking": true,
             "columns": {
                 "prompt": "instruction",
                 "query": "input",
                 "chosen": "chosen",
                 "rejected": "rejected"
             }
         }
     ```

4. æ¨¡å‹åå¥½è®­ç»ƒï¼Œ`run_train.py`

   ```
   python run_train.py \
           --train_method ipo \
           --dataset test_dataset_name \
           --output output_folder/xxxxxxxx \
           --mode "dpo"
   ```

   å…¶ä¸­ï¼Œ`--train_method ipo`å¯ä»¥æ›¿æ¢ä¸º`dpo`æˆ–è€…`orpo`ï¼Œæ³¨æ„ä¿®æ”¹`--output`åˆ°ä½ æƒ³è¦çš„æ¨¡å‹ä¿å­˜çš„ä½ç½®ï¼›è®­ç»ƒç»“æŸååœ¨outputæ–‡ä»¶å¤¹ä¸­ä½ ä¼šæ‰¾åˆ°ä¸€ä¸ª`xxx-merged`æ–‡ä»¶å¤¹ï¼Œè¿™ä¸ªå°±æ˜¯æœ€ç»ˆä¿å­˜çš„æ¨¡å‹ckptç»“æœ

5. å¯¹è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œ`vllm_sample_offline.py`

   ```
   CUDA_VISIBLE_DEVICES=0,1,2,3 python vllm_sample_offline.py --model xxxx_path_to_merged_model --dataset zte --fewshot yes --sample_n 1 --split test --run_split 1 --fewshot_path xxxx_fewshot.json
   ```

   æ³¨æ„ä¿®æ”¹`--model`å‚æ•°ä¸ºåˆšæ‰å¾—åˆ°çš„`xxx-merged`æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚æœä½¿ç”¨fewshotï¼Œä½ ä¹Ÿå¯ä»¥æŒ‡å®š`--fewshot_path xxxx_fewshot.json`å‚æ•°


   # Knowledge Distillation







